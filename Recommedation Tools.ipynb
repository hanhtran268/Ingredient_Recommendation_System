{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062d1af9-91d7-4ea2-a153-956775f9c217",
   "metadata": {},
   "source": [
    "# **Recommendation Tools - Group Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48f8e4-79fa-4a54-9fc1-c4d61c69f254",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Set-up the enviroment and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ff6c2f-079f-4e07-a402-328aa8a074a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hanhtran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hanhtran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/hanhtran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hanhtran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hanhtran/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from ieseg_recsys import eval, model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD\n",
    "from collections import Counter\n",
    "\n",
    "# NLP packages\n",
    "import nltk # pip install nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure necessary NLTK resources are available\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c598d9f-2b55-45e1-af0a-3cfc992311e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading data\n",
    "\n",
    "# Train data\n",
    "data= pd.read_csv('train.csv')\n",
    "\n",
    "# Meta data\n",
    "meta= pd.read_csv('metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "611f61db-d190-490e-9a9b-ffcb8226712a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train data: 165226\n",
      "Length of Meta data: 231637\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Train data:\", len(data))\n",
    "print(\"Length of Meta data:\", len(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d42d224-06a6-4d48-a0f1-0a8b129a08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "filtered_meta = pd.merge(meta[['id', 'ingredients','nutrition']], data, left_on='id', right_on='recipe_id', how='inner')\n",
    "\n",
    "# Convert the format of some column to list\n",
    "filtered_meta['ingredients'] = filtered_meta['ingredients'].apply(ast.literal_eval)\n",
    "filtered_meta['nutrition'] = filtered_meta['nutrition'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc36975-afa9-4491-9bb8-6a52b4ea54fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.964043189328557\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average ingredient for each recipe (we can use it later for evaluation metric)\n",
    "filtered_meta['ingredient_count'] = filtered_meta['ingredients'].apply(lambda x: len(x))\n",
    "print(filtered_meta['ingredient_count'].mean())\n",
    "\n",
    "# Drop unnecesary col\n",
    "filtered_meta = filtered_meta.drop(columns=['ingredient_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33940c7-efaf-4945-9531-4472c0188f4c",
   "metadata": {},
   "source": [
    "**We will choose top-N = 8 as 8 is the average ingredient for each recipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572019f6-56ec-4ab7-a71b-d3bacb6e882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the healthiness score\n",
    "def calculate_health_score(row):\n",
    "    calories, total_fat, sugar, sodium, protein, sat_fat, carbs = row['nutrition']\n",
    "    return (protein - total_fat - sugar - sodium / 240 - sat_fat)  # Penalize both total fat and saturated fat\n",
    "\n",
    "# Apply the health score calculation\n",
    "filtered_meta['health_score'] = filtered_meta.apply(calculate_health_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a0fe37-540a-48c7-bc3b-6ee3c077bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing such that scores are scaled between 1 and 2\n",
    "filtered_meta['normalized_health_score'] = 1 + (filtered_meta['health_score'] - filtered_meta['health_score'].min()) / (filtered_meta['health_score'].max() - filtered_meta['health_score'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85cc5d5-8988-4c79-a987-c9f7d4d8d5a5",
   "metadata": {},
   "source": [
    "# 2. Solution 1: \n",
    "## Non-personalized ingredient recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b8500-f380-49b4-8f0a-415d67f2875f",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4c5420-7c0a-4f48-8ac3-af0de658b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          object\n",
       "ingredients                 object\n",
       "nutrition                   object\n",
       "user_id                     object\n",
       "recipe_id                   object\n",
       "date                        object\n",
       "rating                       int64\n",
       "review                      object\n",
       "health_score               float64\n",
       "normalized_health_score    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2617b5-58b9-46c7-9203-5204a9d5b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and handle them\n",
    "filtered_meta = filtered_meta.dropna(subset=['ingredients', 'rating', 'review'])\n",
    "\n",
    "# Normalize the ingredients text\n",
    "filtered_meta['ingredients'] = filtered_meta['ingredients'].apply(lambda x: [i.lower().strip() for i in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000b1c32-ba55-46a9-bab9-18696f179623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime format\n",
    "filtered_meta['date'] = pd.to_datetime(filtered_meta['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee10dcb-d758-4a62-96d5-e78a49297552",
   "metadata": {},
   "source": [
    "### Step 2: Analyze User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aced4ed-c573-4959-a701-d701d3a4e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to get the sentiment of the review\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis\n",
    "filtered_meta['sentiment'] = filtered_meta['review'].apply(get_sentiment)\n",
    "\n",
    "# Consider reviews with positive sentiment and high ratings\n",
    "df_positive = filtered_meta[(filtered_meta['sentiment'] > 0) & (filtered_meta['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f27fd1c-5d0f-4ed3-8ed2-404067e5d147",
   "metadata": {},
   "source": [
    "### Step 3: Non-Personal Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3be62627-bb0d-48ff-bf14-70480acbf0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ingredients based on positive reviews and high ratings:\n",
      "[('salt', 62328), ('butter', 40258), ('sugar', 31460), ('onion', 26781), ('water', 24737), ('eggs', 24218), ('flour', 21854), ('olive oil', 18786), ('milk', 18622), ('brown sugar', 15746)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of ingredients in positive reviews\n",
    "all_ingredients = [item for sublist in df_positive['ingredients'].tolist() for item in sublist]\n",
    "\n",
    "# Count the frequency of each ingredient\n",
    "ingredient_counts = Counter(all_ingredients)\n",
    "\n",
    "# Get the most common ingredients\n",
    "top_ingredients = ingredient_counts.most_common(10)  \n",
    "\n",
    "# Display top ingredients\n",
    "print(\"Top 10 ingredients based on positive reviews and high ratings:\")\n",
    "print(top_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1acbdd6-365d-4cc2-ae4a-f2e670e39387",
   "metadata": {},
   "source": [
    "### Step 4: Non-Personal Recommendation with Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33dfada2-d4e1-4da3-aa50-842fdf689689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Ingredients Based on Recency:\n",
      "                                       adj_rating\n",
      "ingredients                                      \n",
      "cranberry muffin mix                     5.983784\n",
      "peanut butter filled pretzels            5.971310\n",
      "mistake                                  5.968815\n",
      "nestle swirled holiday morsels           5.967568\n",
      "peameal bacon                            5.958836\n",
      "ritz bits mini peanut butter crackers    5.942620\n",
      "vegetable crackers                       5.942620\n",
      "butter-flavored oil                      5.942620\n",
      "korean radishes                          5.931393\n",
      "wontons                                  5.911435\n"
     ]
    }
   ],
   "source": [
    "# Compute the difference in days\n",
    "newest = filtered_meta['date'].max()\n",
    "filtered_meta['days_diff'] = (newest - filtered_meta['date']).dt.days\n",
    "\n",
    "# Normalize the 'days_diff' to a score between 0 and 1\n",
    "max_days = filtered_meta['days_diff'].max()\n",
    "filtered_meta['recency_score'] = 1 - (filtered_meta['days_diff'] / max_days)\n",
    "\n",
    "# Add recency score\n",
    "filtered_meta['adj_rating'] = filtered_meta['rating'] * filtered_meta['recency_score']\n",
    "\n",
    "# Explode the ingredients list into individual rows\n",
    "expanded_meta = filtered_meta.explode('ingredients')\n",
    "\n",
    "# Compute the mean of adjusted ratings\n",
    "ingredient_ratings = expanded_meta.groupby('ingredients').agg({\n",
    "    'adj_rating': 'mean'\n",
    "}).sort_values('adj_rating', ascending=False)\n",
    "\n",
    "# Display top ingredients\n",
    " = ingredient_ratings.nlargest(10, 'adj_rating')\n",
    "print(\"Top 10 Ingredients Based on Recency:\")\n",
    "print(top_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c30c2-94a2-4c90-98b6-a8d9017a1ec0",
   "metadata": {},
   "source": [
    "# 3. Solution 2: \n",
    "## Personalized ingredient recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c7f11-058b-4e37-a449-662c1a4b12f6",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70df80f9-4c69-492a-8bd4-3ebd05c79a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'ingredient' column from list of ingredients to separate rows\n",
    "df = filtered_meta.explode('ingredients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed240a79-55c6-4440-8917-db7ca5e7ff35",
   "metadata": {},
   "source": [
    "### Step 2: Calculate weight-rating for ingredient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d11f4d-f146-48c6-84ea-1adc32b32984",
   "metadata": {},
   "source": [
    "How it works?\n",
    "1. Assign Weight: Ratings from recipes with fewer ingredients might be given more weight for each ingredient, assuming that the taste of each ingredient has a stronger impact in simpler recipes.\n",
    "2. Calculate Weighted Average: For each ingredient, sum the product of the ratings and their corresponding weights, and then divide by the sum of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd4df9e-d02d-4f5f-9842-169f53f8b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213599/606941224.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_df = df.groupby(['user_id', 'ingredients']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Assign basic weights based on recipe size\n",
    "df['weight'] = 1 / df.groupby('recipe_id')['ingredients'].transform('size')\n",
    "\n",
    "# Calculate the weighted rating and sentiment using adjusted weights\n",
    "df['weighted_rating'] = df['rating'] * df['weight']\n",
    "\n",
    "# Calculate weighted ratings, sum of weights, and average sentiment using adjusted weights\n",
    "final_df = df.groupby(['user_id', 'ingredients']).apply(\n",
    "    lambda x: pd.Series({\n",
    "        'ingredient_rating': x['weighted_rating'].sum() / x['weight'].sum(),\n",
    "        'reviews': \" | \".join(x['review'].astype(str)) \n",
    "    })\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b484222-18e9-42ec-b5cd-b8128fca456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the 'ingredient_rating' to the nearest integer and convert to int\n",
    "final_df['ingredient_rating_int'] = final_df['ingredient_rating'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19214a14-5b3a-479b-9c24-80cb14df643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum ingredient rating: 1.0\n",
      "Maximum ingredient rating: 6.000000000000003\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the new range of rating\n",
    "min_rating = final_df['ingredient_rating'].min()\n",
    "max_rating = final_df['ingredient_rating'].max()\n",
    "\n",
    "print(\"Minimum ingredient rating:\", min_rating)\n",
    "print(\"Maximum ingredient rating:\", max_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c237176-4245-4d68-8cbc-044e266d3fcc",
   "metadata": {},
   "source": [
    "### Step 3: Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ff51f-32cd-4ca4-a524-2c2a1cf1d91b",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0d531a0-4404-4213-b41b-a3c570b3f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract only necessary cols\n",
    "data = final_df[['user_id', 'ingredients', 'ingredient_rating']]\n",
    "\n",
    "# train-test split\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "# reset index\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c568ba70-2a73-4eba-8949-64b92da2c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train ------\n",
      "Nr items: 9233\n",
      "Nr users: 11346\n",
      "\n",
      "------ Test ------\n",
      "Nr items: 7416\n",
      "Nr users: 11344\n",
      "\n",
      "Nr new items: 725\n",
      "Nr new users: 0\n"
     ]
    }
   ],
   "source": [
    "# Inspecting data\n",
    "print('------ Train ------')\n",
    "print('Nr items:', len(train[\"ingredients\"].unique()))\n",
    "print('Nr users:', len(train[\"user_id\"].unique()))\n",
    "\n",
    "print('\\n------ Test ------')\n",
    "print('Nr items:', len(test[\"ingredients\"].unique()))\n",
    "print('Nr users:', len(test[\"user_id\"].unique()))\n",
    "\n",
    "print('\\nNr new items:', len(set(test[\"ingredients\"])-set(train[\"ingredients\"])))\n",
    "print('Nr new users:', len(set(test[\"user_id\"])-set(train[\"user_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7a3917-f97c-436b-8616-7721e3c21d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting the train-test set\n",
    "\n",
    "# Update the rating scale \n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "\n",
    "# Loading and Preparing Training Data\n",
    "df_train = Dataset.load_from_df(train, reader).build_full_trainset()\n",
    "\n",
    "# Loading and Preparing Testing Data\n",
    "df_test = list(test.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc78ca3-e4d2-4be1-b546-7fde45687210",
   "metadata": {},
   "source": [
    "### User-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ecc4286-0c96-414b-b1a9-520122a2b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "80842a1b-b0ca-4731-bec4-ee65a7de45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best RMSE: 1.07021764728033\n",
      "Best parameters: {'k': 20, 'sim_options': {'name': 'cosine', 'user_based': True}}\n"
     ]
    }
   ],
   "source": [
    "# Set the scale\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "data = Dataset.load_from_df(train[['user_id', 'ingredients', 'ingredient_rating']], reader)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'k': [10, 15, 20], \n",
    "    'sim_options': {\n",
    "        'name': ['cosine'],  \n",
    "        'user_based': [True]  }\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "# Perform grid search\n",
    "gs.fit(data)\n",
    "\n",
    "# Output the best score and parameters\n",
    "print('Best RMSE:', gs.best_score['rmse'])\n",
    "print('Best parameters:', gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1a9e1f55-4e1a-48b9-8ec9-51282c00a632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the best ib model \n",
    "ub_best_model = KNNBasic(k=20, min_k=5, sim_options={'name': 'cosine', 'user_based': True}, random_state=42)\n",
    "\n",
    "# Fit on training set\n",
    "ub_best_model.fit(df_train)\n",
    "\n",
    "# Predict on testset\n",
    "ub_pred = ub_best_model.test(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5bc7cf7b-a072-490c-ad81-8f50b6e4c23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_based_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.078202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.555197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.999910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.941100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.969614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@8</th>\n",
       "      <td>0.836824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User_based_15\n",
       "RMSE            1.078202\n",
       "MAE             0.555197\n",
       "Recall          0.999910\n",
       "Precision       0.941100\n",
       "F1              0.969614\n",
       "NDCG@8          0.836824"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "ub_res = eval.evaluate(ub_pred, topn=8, rating_cutoff=4).rename(columns={'value':'User_based_15'})\n",
    "ub_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1b8f5-b5ba-45f7-9bbe-dee2f28ffce8",
   "metadata": {},
   "source": [
    "### Item-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "329d03d0-986a-4794-ae4f-e527ff4aa136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best RMSE: 0.9519515892555729\n",
      "Best parameters: {'k': 20, 'sim_options': {'name': 'cosine', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "# Set the scale\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "data = Dataset.load_from_df(train[['user_id', 'ingredients', 'ingredient_rating']], reader)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'k': [5, 10, 15, 20], \n",
    "    'sim_options': {\n",
    "        'name': ['cosine'],  \n",
    "        'user_based': [False]  }\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "# Perform grid search\n",
    "gs.fit(data)\n",
    "\n",
    "# Output the best score and parameters\n",
    "print('Best RMSE:', gs.best_score['rmse'])\n",
    "print('Best parameters:', gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ec69485-8286-4bf3-86d6-d9227a081912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the best ib model \n",
    "ib_best_model = KNNBasic(k=20, sim_options={'name': 'cosine', 'user_based': False}, random_state=42)\n",
    "\n",
    "# Fit on training set\n",
    "ib_best_model.fit(df_train)\n",
    "\n",
    "# Predict on testset\n",
    "ib_pred = ib_best_model.test(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "165b4691-bde5-472c-9516-182e7f7130f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_based_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.936958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.559275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.990618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.949343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.969541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@8</th>\n",
       "      <td>0.854787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Item_based_15\n",
       "RMSE            0.936958\n",
       "MAE             0.559275\n",
       "Recall          0.990618\n",
       "Precision       0.949343\n",
       "F1              0.969541\n",
       "NDCG@8          0.854787"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "ib_res = eval.evaluate(ib_pred, topn=8, rating_cutoff=4).rename(columns={'value':'Item_based_15'})\n",
    "ib_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85958e11-0911-436f-afd6-47dc90758976",
   "metadata": {},
   "source": [
    "### Step 4: Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe77160b-cc1f-4849-925a-0da447ab5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99d46a14-24c2-462f-b62a-8f66367c2ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 0.942863830043716\n",
      "Best parameters: {'n_factors': 100, 'n_epochs': 30, 'reg_all': 0.1, 'lr_all': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Set the scale\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "data = Dataset.load_from_df(train[['user_id', 'ingredients', 'ingredient_rating']], reader)\n",
    "\n",
    "# Define a grid of SVD hyperparameters\n",
    "param_grid = {\n",
    "    'n_factors': [10, 20, 50, 100], \n",
    "    'n_epochs': [10, 20, 30],       \n",
    "    'reg_all': [0.1, 0.2, 0.4, 0.5], \n",
    "    'lr_all': [0.005, 0.01, 0.05]   \n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "# Fit GridSearchCV using the Dataset object\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
    "print(\"Best parameters:\", gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83e805fc-6cf4-498c-8f6a-b8d589f63476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the best SVD model \n",
    "mf_best_model = SVD(\n",
    "    n_factors=100, \n",
    "    n_epochs=30, \n",
    "    reg_all=0.1, \n",
    "    lr_all=0.01\n",
    ") \n",
    "\n",
    "# Fit on training set\n",
    "mf_best_model.fit(df_train)\n",
    "\n",
    "# Predict on testset\n",
    "mf_pred = mf_best_model.test(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d5d8875c-a028-465f-b4b4-525256f13ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVD_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.921728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.562667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.994322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.948492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.970866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@8</th>\n",
       "      <td>0.850724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SVD_20\n",
       "RMSE       0.921728\n",
       "MAE        0.562667\n",
       "Recall     0.994322\n",
       "Precision  0.948492\n",
       "F1         0.970866\n",
       "NDCG@8     0.850724"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_res = eval.evaluate(mf_pred, topn=8, rating_cutoff=4).rename(columns={'value':'SVD_20'})\n",
    "mf_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3d95a-cd5c-4915-bc18-1513dffa9254",
   "metadata": {},
   "source": [
    "### Step 5: Content based Model - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19cc50e9-be11-416d-9c0a-b1caf411fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hanhtran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hanhtran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from ieseg_recsys import eval, model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD\n",
    "import re\n",
    "\n",
    "# NLP packages\n",
    "import nltk # pip install nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64302726-6ee2-4c0e-87ce-167bf5da31ca",
   "metadata": {},
   "source": [
    "#### 5.1. Preprocessing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "96d401b3-1368-43e9-a27a-f1467250ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only 60% of the data\n",
    "content_data = final_df.sample(frac=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8ae12956-70b2-4110-96af-b8ea66637243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up data\n",
    "text = content_data[['ingredients','reviews']]\n",
    "data = content_data[['user_id', 'ingredients', 'ingredient_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cb5e1889-d2e5-4953-96dc-f81a9e19a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2af53fbe-fac0-4b76-af93-acfcf8e72292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('nan')  \n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I | re.A)\n",
    "    text = text.lower().strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    return ' '.join(filtered_tokens)\n",
    "    \n",
    "# Apply the preprocessing function to each review\n",
    "processed_reviews = text['reviews'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa38562-aa7b-48ff-b66c-740915aa898a",
   "metadata": {},
   "source": [
    "#### 5.2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1467bba9-a4e9-4fea-a067-5b66e9dde472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad</th>\n",
       "      <th>add</th>\n",
       "      <th>also</th>\n",
       "      <th>bake</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>bit</th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "      <th>cake</th>\n",
       "      <th>...</th>\n",
       "      <th>turn</th>\n",
       "      <th>use</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>well</th>\n",
       "      <th>whole</th>\n",
       "      <th>wonder</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingredients</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low-fat flour tortillas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow mustard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chili powder</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asparagus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336204</td>\n",
       "      <td>0.175431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beef sirloin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ad  add  also  bake  best    better  bit  bread  \\\n",
       "ingredients                                                                 \n",
       "low-fat flour tortillas  0.0  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   \n",
       "yellow mustard           0.0  0.0   0.0   0.0   0.0  0.192898  0.0    0.0   \n",
       "chili powder             0.0  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   \n",
       "asparagus                0.0  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   \n",
       "beef sirloin             0.0  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   \n",
       "\n",
       "                         butter  cake  ...      turn       use  want  \\\n",
       "ingredients                            ...                             \n",
       "low-fat flour tortillas     0.0   0.0  ...  0.000000  0.000000   0.0   \n",
       "yellow mustard              0.0   0.0  ...  0.000000  0.094578   0.0   \n",
       "chili powder                0.0   0.0  ...  0.000000  0.000000   0.0   \n",
       "asparagus                   0.0   0.0  ...  0.336204  0.175431   0.0   \n",
       "beef sirloin                0.0   0.0  ...  0.000000  0.184706   0.0   \n",
       "\n",
       "                              way  well  whole    wonder  work  would  yummi  \n",
       "ingredients                                                                   \n",
       "low-fat flour tortillas  0.000000   0.0    0.0  0.000000   0.0    0.0    0.0  \n",
       "yellow mustard           0.000000   0.0    0.0  0.000000   0.0    0.0    0.0  \n",
       "chili powder             0.000000   0.0    0.0  0.000000   0.0    0.0    0.0  \n",
       "asparagus                0.345979   0.0    0.0  0.000000   0.0    0.0    0.0  \n",
       "beef sirloin             0.000000   0.0    0.0  0.324545   0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "dtm = tfidf.fit_transform(processed_reviews)\n",
    "\n",
    "# Convert DTM to DataFrame for content-based model\n",
    "df_dtm = pd.DataFrame(dtm.toarray(), columns=tfidf.get_feature_names_out(), index=text['ingredients'])\n",
    "\n",
    "# Convert all columns of the DataFrame to float32\n",
    "df_dtm = df_dtm.astype('float32')\n",
    "df_dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8906a-667b-427a-939e-cebd33d9b49f",
   "metadata": {},
   "source": [
    "#### 5.3. Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb22790e-66b0-4d53-90bd-62001e219cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for content-based model\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "df_train = Dataset.load_from_df(train[['user_id', 'ingredients', 'ingredient_rating']], reader).build_full_trainset()\n",
    "df_test = list(test.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ebfe135-1f6b-49d9-ac9e-933dc38983e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate indices found: Index(['eggs', 'pepper', 'water', 'olive oil', 'parmesan cheese',\n",
      "       'black pepper', 'butter', 'buttermilk', 'feta cheese', 'oatmeal',\n",
      "       ...\n",
      "       'fuyu persimmons', 'frozen potato slices',\n",
      "       'duncan hines moist deluxe yellow cake mix', 'bear roast',\n",
      "       'chicken consomme', 'butterfinger candy bar', 'sago',\n",
      "       'maggi 2-minute noodles', 'diced tomatoes with seasonings',\n",
      "       'colored sugar sprinkle'],\n",
      "      dtype='object', name='ingredients', length=6786)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate indices in df_dtm\n",
    "if df_dtm.index.duplicated().any():\n",
    "    print(\"Duplicate indices found:\", df_dtm.index[df_dtm.index.duplicated()].unique())\n",
    "else:\n",
    "    print(\"No duplicate indices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "feed7004-20d5-480a-8d46-339ffd3f82f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanhtran/miniconda3/envs/tf2/lib/python3.10/site-packages/ieseg_recsys/model.py:72: RuntimeWarning: invalid value encountered in divide\n",
      "  self.prediction = (np.matmul(df_pivot.values, self.matrixNN) / denom) + self.user_avg[:,np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "# Resolve duplicates by averaging the features of duplicate items\n",
    "df_dtm = df_dtm.groupby(df_dtm.index).mean()\n",
    "\n",
    "# Initialize and fit the content-based model\n",
    "cb = model.ContentBased(NN=5)\n",
    "cb.fit(df_dtm)\n",
    "cb.fit_ratings(df_train)\n",
    "\n",
    "# Predict test ratings\n",
    "cb_pred = cb.test(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5d98ec7e-fa45-4b4e-a6bb-90d4b457724a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CB_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.952692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.576139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.992290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.948229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.969759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@8</th>\n",
       "      <td>0.854672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CB_model\n",
       "RMSE       0.952692\n",
       "MAE        0.576139\n",
       "Recall     0.992290\n",
       "Precision  0.948229\n",
       "F1         0.969759\n",
       "NDCG@8     0.854672"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "cb_res = eval.evaluate(cb_pred, topn=8, rating_cutoff=4).rename(columns={'value':'CB_model'})\n",
    "cb_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098c602-f00c-415d-ac28-c8c102610aa9",
   "metadata": {},
   "source": [
    "# 4. Finding best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a5a59aa-9a2e-426d-8cc4-4243798e52a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">IB_model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">UB_model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MF_model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CB_TFIDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Item_based_15</th>\n",
       "      <th>Model</th>\n",
       "      <th>User_based_15</th>\n",
       "      <th>Model</th>\n",
       "      <th>SVD_20</th>\n",
       "      <th>Model</th>\n",
       "      <th>CB_model</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936958</td>\n",
       "      <td>IB_model</td>\n",
       "      <td>1.078202</td>\n",
       "      <td>UB_model</td>\n",
       "      <td>0.921728</td>\n",
       "      <td>MF_model</td>\n",
       "      <td>0.952692</td>\n",
       "      <td>CB_TFIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.559275</td>\n",
       "      <td>IB_model</td>\n",
       "      <td>0.555197</td>\n",
       "      <td>UB_model</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>MF_model</td>\n",
       "      <td>0.576139</td>\n",
       "      <td>CB_TFIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.990618</td>\n",
       "      <td>IB_model</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>UB_model</td>\n",
       "      <td>0.994322</td>\n",
       "      <td>MF_model</td>\n",
       "      <td>0.992290</td>\n",
       "      <td>CB_TFIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.949343</td>\n",
       "      <td>IB_model</td>\n",
       "      <td>0.941100</td>\n",
       "      <td>UB_model</td>\n",
       "      <td>0.948492</td>\n",
       "      <td>MF_model</td>\n",
       "      <td>0.948229</td>\n",
       "      <td>CB_TFIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969541</td>\n",
       "      <td>IB_model</td>\n",
       "      <td>0.969614</td>\n",
       "      <td>UB_model</td>\n",
       "      <td>0.970866</td>\n",
       "      <td>MF_model</td>\n",
       "      <td>0.969759</td>\n",
       "      <td>CB_TFIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.854787</td>\n",
       "      <td>IB_model</td>\n",
       "      <td>0.836824</td>\n",
       "      <td>UB_model</td>\n",
       "      <td>0.850724</td>\n",
       "      <td>MF_model</td>\n",
       "      <td>0.854672</td>\n",
       "      <td>CB_TFIDF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IB_model                UB_model            MF_model            \\\n",
       "  Item_based_15     Model User_based_15     Model    SVD_20     Model   \n",
       "0      0.936958  IB_model      1.078202  UB_model  0.921728  MF_model   \n",
       "1      0.559275  IB_model      0.555197  UB_model  0.562667  MF_model   \n",
       "2      0.990618  IB_model      0.999910  UB_model  0.994322  MF_model   \n",
       "3      0.949343  IB_model      0.941100  UB_model  0.948492  MF_model   \n",
       "4      0.969541  IB_model      0.969614  UB_model  0.970866  MF_model   \n",
       "5      0.854787  IB_model      0.836824  UB_model  0.850724  MF_model   \n",
       "\n",
       "   CB_TFIDF            \n",
       "   CB_model     Model  \n",
       "0  0.952692  CB_TFIDF  \n",
       "1  0.576139  CB_TFIDF  \n",
       "2  0.992290  CB_TFIDF  \n",
       "3  0.948229  CB_TFIDF  \n",
       "4  0.969759  CB_TFIDF  \n",
       "5  0.854672  CB_TFIDF  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index if necessary\n",
    "ib_res.reset_index(drop=True, inplace=True)\n",
    "ub_res.reset_index(drop=True, inplace=True)\n",
    "mf_res.reset_index(drop=True, inplace=True)\n",
    "cb_res.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a model identifier column directly (if not already done)\n",
    "ib_res['Model'] = 'IB_model'\n",
    "ub_res['Model'] = 'UB_model'\n",
    "mf_res['Model'] = 'MF_model'\n",
    "cb_res['Model'] = 'CB_TFIDF'\n",
    "\n",
    "# Concatenate all DataFrames along the columns\n",
    "comparison_df = pd.concat([ib_res, ub_res, mf_res, cb_res], axis=1, keys=['IB_model', 'UB_model', 'MF_model', 'CB_TFIDF'])\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63227815-f443-43ef-b8d7-b0fc629cb84b",
   "metadata": {},
   "source": [
    "#### **Evaluation Metrics for Top-N Recommendation Systems**\r\n",
    "\r\n",
    "To find the best model for a top-N recommendation task, we need to focus on metrics that best reflect the effectiveness of ranking and relevance in top-N recommendations. Typically, these include:\r\n",
    "\r\n",
    "- **Precision**: This measures the accuracy of the recommendations provided to the user, focusing on the proportion of relevant items within the top-N suggested items.\r\n",
    "\r\n",
    "- **Recall**: This metric evaluates how many of the relevant items are captured in the top-N recommendations compared to the total available relevant items.\r\n",
    "\r\n",
    "- **NDCG (Normalized Discounted Cumulative Gain)**: NDCG accounts for the position of the correct recommendations within the list, providing a more nuanced view of the recommendation system's effectiveness at ranking higher quality recommendations higher in te list.\r\n",
    "s in the top positions\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29a856-00b2-4bdc-8039-80e64f038c0b",
   "metadata": {},
   "source": [
    "#### **Model Performance Analysis Based on Key Metrics**\n",
    "\n",
    "- **MF-model** appears to have a well-balanced performance across all metrics, with a particularly high F1 score and precision. It also has a good RMSE and NDCG@8, suggesting that it ranks items effectively and accurately predicts ratings.\n",
    "\n",
    "- **Item-based** collaborative filtering shows strength in precision and RMSE compared to **User-based**, which indicates better prediction and ranking accuracy.\n",
    "**CB-model** performs well in terms of recall, which is beneficial if the priority is not to miss any potentially relevant recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77c3be-9ed5-4737-84c0-88a987c899bb",
   "metadata": {},
   "source": [
    "#### **Conclusion**: \n",
    "**MF-model** would be the best choice given its strong overall performance in precision, F1 score, and NDCG@8. This model balances the trade-offs between different metrics effectively, making it suitable for generating top N recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c74fc1-1ca1-4bca-b7d1-cc1e7ef4eca2",
   "metadata": {},
   "source": [
    "# 5. Recipe suggestion based on the ingredient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb07715-7ed8-429a-8eea-9b46de00961e",
   "metadata": {},
   "source": [
    "Step 1: After identifying the best model - MF model for ingredient recommendation, we proceed to extract the top 15 ingredients for each user and then locate the corresponding matched recipes.\r\n",
    "\r\n",
    "Step 2: Finally, based on the previously calculated healthy scores, we propose the best ingredients and recipes that promote healthier options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df00df-7227-4a2c-999c-ac39eed77a45",
   "metadata": {},
   "source": [
    "### 5.1. Extract top 15 ingredient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bfbb4437-fc2a-4376-9bed-9bbe9a4d8e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213599/1115695908.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_ingredients_per_user = pred_df.groupby('user_id').apply(\n"
     ]
    }
   ],
   "source": [
    "# Convert predictions (on test set) to DataFrame. Using prediction from matrix factorization model\n",
    "data = {\n",
    "    'user_id': [pred.uid for pred in mf_pred],\n",
    "    'ingredient_id': [pred.iid for pred in mf_pred],\n",
    "    'predicted_rating': [pred.r_ui for pred in mf_pred]}\n",
    "\n",
    "pred_df = pd.DataFrame(data)\n",
    "\n",
    "# Group by user_id and apply sorting within groups to get top 15 ingredients\n",
    "top_ingredients_per_user = pred_df.groupby('user_id').apply(\n",
    "    lambda x: x.nlargest(15, 'predicted_rating')\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "543ab21f-274b-4b66-ae3f-25eb629046e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recipe dataframe\n",
    "recipes_df = filtered_meta[['recipe_id','ingredients','normalized_health_score']]\n",
    "\n",
    "# Remove duplicates:\n",
    "recipes_df = recipes_df.drop_duplicates(subset=['recipe_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6fd54-3bac-472c-8059-cdb94f75542e",
   "metadata": {},
   "source": [
    "### 5.2. Find matching and healthy recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d12dc359-f9bb-4615-b289-e5f3c3e65e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_recipes(recipes_df, top_ingredients):\n",
    "    \"\"\"Calculate scores for recipes based on matching ingredients and health scores.\"\"\"\n",
    "    # Calculate match scores \n",
    "    recipes_df['match_score'] = recipes_df['ingredients'].apply(lambda x: sum(ingredient in x for ingredient in top_ingredients))\n",
    "    # Calculate final scoring with heathy score\n",
    "    recipes_df['final_score'] = recipes_df['match_score'] * recipes_df['normalized_health_score']\n",
    "    # Sort by final score \n",
    "    return recipes_df.sort_values(by='final_score', ascending=False)\n",
    "\n",
    "def recommend_recipes_for_user(user_id, top_ingredients_per_user, recipes_df):\n",
    "    \"\"\"Find and recommend top recipes for a specific user based on their top ingredients.\"\"\"\n",
    "    if user_id in top_ingredients_per_user['user_id'].values:\n",
    "        top_ingredients = top_ingredients_per_user.loc[top_ingredients_per_user['user_id'] == user_id, 'ingredient_id'].tolist()\n",
    "        recommended_recipes = score_recipes(recipes_df.copy(), top_ingredients)\n",
    "        return recommended_recipes.head()\n",
    "    else:\n",
    "        return pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3d95aa73-cda1-4c54-a851-324125693e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       recipe_id                                        ingredients  \\\n",
      "130097  R9184992  [medium pasta shell, salt, vegetable oil, baco...   \n",
      "164921  R5004845  [hard-boiled eggs, all-purpose flour, pork sau...   \n",
      "15128   R9349626  [lean lamb stew meat, salt, pepper, all-purpos...   \n",
      "45733   R6500995  [rabbit, olive oil, potatoes, carrots, onion, ...   \n",
      "41289   R8699701  [vegetable oil, carrots, onion, green pepper, ...   \n",
      "\n",
      "        normalized_health_score  match_score  final_score  \n",
      "130097                 1.948310            5     9.741548  \n",
      "164921                 1.947599            5     9.737995  \n",
      "15128                  1.951225            4     7.804899  \n",
      "45733                  1.950642            4     7.802568  \n",
      "41289                  1.950475            4     7.801899  \n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "user_id_example = 'U5879070'  # Use an actual user ID from your dataset\n",
    "recommended_recipes = recommend_recipes_for_user(user_id_example, top_ingredients_per_user, recipes_df)\n",
    "\n",
    "if not recommended_recipes.empty:\n",
    "    print(recommended_recipes)  \n",
    "else:\n",
    "    print('No matching recipes found for user:', user_id_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72756c1d-9f92-4bed-a4af-fc368b219dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
